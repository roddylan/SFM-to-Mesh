%% bare_conf_compsoc.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE Computer
%% Society conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference,compsoc]{IEEEtran}
% Some/most Computer Society conferences require the compsoc mode option,
% but others may want the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference,compsoc]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.





\usepackage[hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage{enumerate}
% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.
%
% Note that some packages require special options to format as the Computer
% Society requires. In particular, Computer Society  papers do not use
% compressed citation ranges as is done in typical IEEE papers
% (e.g., [1]-[4]). Instead, they list every citation separately in order
% (e.g., [1], [2], [3], [4]). To get the latter we need to load the cite
% package with the nocompress option which is supported by cite.sty v4.0
% and later.





% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
\usepackage{tabularray}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
 \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
 \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix



\usepackage{multirow}
% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{SFM-MVS to Mesh}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Roderick Lan}
\IEEEauthorblockA{1706751}
\and
\IEEEauthorblockN{Abdullah Khadeli}
\IEEEauthorblockA{1722102}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page (and note that there is less available width in this regard for
% compsoc conferences compared to traditional conferences), use this
% alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
    Structure From Motion (SFM) and Multiview Stereo (MVS) are computer vision
    algorithms commonly found in a wide range of domains and use cases, 
    one of the most prevalent being photogrammetry. In this project, 
    we investigate the ideal methodology and object properties for photogrammetry 
    of specific objects using SFM, and explore an altered approach to the feature 
    extraction and feature matching steps in the algorithm. Additionally, we evaluate 
    the effectiveness of two algorithms for surface reconstruction on our SFM-MVS 
    (point cloud) outputs. 
\end{abstract}

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
One of the most common applications of Structure From Motion (SFM) 
and Multiview Stereo (MVS) is in photogrammetry. These two techniques 
are complementary to each other, and result in a dense point cloud reconstruction 
of an object (or environment) from image data. However, in many fields where 
photogrammetry is used, a 3D mesh is likely more useful than a point cloud is. 
As such, time is often spent cleaning resultant point clouds and converting them 
to meshes, when the brunt of this process could be automated and simplified. 
Furthermore, SFM can be relatively slow for many datasets. The general outline of 
SFM algorithms involves feature extraction, feature matching, triangulation and 
bundle adjustment. Each of these steps can take considerable time, however there 
is not much to change with regards to triangulation and bundle adjustment. 
On the other hand, feature extraction (SIFT \cite{sift} based) and feature 
matching can be altered to be computationally faster at a minimal 
cost to accuracy. In a nutshell, this project report will explore 
proposed alterations to feature extraction and feature matching in SFM, 
investigate the ideal methodologies and object types for this altered 
approach, and evaluate algorithms relating to point cloud processing and 
mesh reconstruction. The source code for the project can be found on
\href{https://github.com/roddylan/SFM-to-Mesh}{GitHub}.

% \hfill mds
 
% \hfill August 26, 2015

% \subsection{Subsection Heading Here}
% Subsection text here.


% \subsubsection{Subsubsection Heading Here}
% Subsubsection text here.


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.


\section{Theory and Technical Details}
This project largely focuses on alterations to SFM and post processing SFM-MVS 
output for mesh construction. The general workflow and steps taken in this project
can be seen in Figure \ref{fig:pipeline} and are the following:
\begin{enumerate}[1.]
    \item We implement a custom BRISK-SIFT feature extraction stack for SFM
    \item We implement feature matching using approximate nearest neighbors
    for speed, with outlier removal from Lowe's Ratio Test \cite{sift} and MAGSAC++ 
    \cite{magsac}
    \item We implement a feature processing method to further simplify key point 
    matches
    \item Our features and matches are used to build sparse and dense reconstructions
    via COLMAP \cite{colmap}
    \item Resultant point clouds are processed and used to generate meshes
\end{enumerate}
\begin{figure}[ht!]
    \centering
    {{\includegraphics[width=.4\textwidth]{figures/pipeline.png} }}
    \caption{Pipeline/Project Workflow}
    \label{fig:pipeline}
  \end{figure}
\subsection{SFM-MVS}
SFM algorithms generally consist of the following steps: 
feature extraction, feature matching, triangulation, and bundle adjustment. 
\\
Traditionally, feature extraction in SFM algorithms use Lowe's 
SIFT approach for both feature detection and description \cite{sift}.
Detection in SIFT involves a Gaussian pyramid-like structure of octaves 
for scale space representation. Each octave of scale space contains a 
set of Gaussian convolved images separated by a scale factor, 
and each octave uses a down-sampled image relative to the previous 
octave. The extrema (within a given window) of a difference-of-Gaussian 
(DoG) (Figure \ref{fig:sift_scale_space}) function applied to adjacent Gaussian images within 
octaves is used to detect stable key points in scale space. 
Mathematically, the scale space is defined as a function 
$L(x,y,\sigma)$, produced from a variable-scale Gaussian,
$G(x,y,\sigma)$ and the input image $I(x,y)$ \cite{sift}:
\[
    L(x,y,\sigma) = G(x,y,\sigma) * I(x,y)
\] where $*$ is the convolution operation. The DoG function takes the form:
\begin{flalign*}
    D(x,y,\sigma) &= (G(x,y,k\sigma) - G(x,y,\sigma)) * I(x,y) \\
    &= L(x,y,k\sigma) - L(x,y,\sigma)
\end{flalign*}
with some constant multiplicative scale factor $k$. 
\begin{figure}[ht!]
    \centering
    {{\includegraphics[width=.4\textwidth]{figures/sift_scale_space.png} }}
    \caption{Difference of Gaussians and Sift Scale Space\\Source: Adapted from \cite{sift}}
    \label{fig:sift_scale_space}
\end{figure}
DoG approximates the normalized Laplacian of Gaussian \cite{lindeberg}
, whose local extrema was shown to correspond to stable key points/blobs. 
SIFT descriptors \cite{sift} take the gradient directions over a 
spatial region around feature points. A histogram of these gradient 
directions (orientations) is normalized and invariant against rotation, 
scale, and brightness. The descriptors are stored as a 128-dimensional 
vector containing these histogram values corresponding to the gradient 
magnitudes and are known for their distinctiveness. BRISK feature detection
\cite{brisk} builds on a computationally optimized version of 
FAST 9-16 adapted for scale invariance via a simplified representation of 
scale space (compared to SIFT \cite{sift}). Due to the simplified scale 
space representation and use of a computationally efficient FAST 9-16 
detection algorithm, BRISK is considerably faster than SIFT while still 
detecting high quality key points. The set of detected points with BRISK is 
similar to many SIFT detected points. Additionally, since both approaches 
revolve around scale, rotation, and illuminance invariance, and since description 
is independent of detection, SIFT descriptors can be easily applied to BRISK key 
points. For the purposes of this project, we rely on OpenCV's 
implementation of both SIFT \cite{siftcv} and BRISK \cite{briskcv}.
Feature matching in SFM (with SIFT descriptors) is done by identifying 
a nearest neighbor (based on L2 distance) between descriptors in 2 views \cite{sift}.
This is efficiently approximated through \cite{fnn}.\\
Lowe's ratio test \cite{sift} compares the distance measures of 
the 2 nearest neighbors and rejects matches where the ratio between the 
distances from these neighbors is greater than or equal to some value $l$ (ie.
$d_1 \ge l \cdot d_2)$, eliminating false matches. \cite{usac}'s 
MAGSAC++ \cite{magsac}, an improved version of RANSAC, further 
refines these matches by finding inliers during a fundamental 
matrix estimation between randomly sampled matches. 
Two view geometry estimation, triangulation and bundle adjustment, 
as well as multiview stereo, are handled through COLMAP \cite{colmap}
\cite{schoenberger2016sfm} \cite{schoenberger2016mvs}, resulting in sparse 
and dense point cloud reconstructions (with estimated surface normals).



\subsubsection{Image Capturing}
Image capturing for SFM was primarily focused on small objects with 
three things in mind:
\begin{enumerate}[1.]
    \item Brightness constancy (via controlled lighting)
    \item Angle variety and image overlap
    \item Limited background noise (via. lightboxes/backdrops as shown in Figure \ref{fig:backdrops})
    (\textit{note: this is not present for some earlier datasets})
\end{enumerate}
\begin{figure}[ht!]
    \subfloat[Black backdrop]{\includegraphics[width=.3\textwidth]{figures/black lbox.png}}
    \
    \subfloat[White backdrop]{\includegraphics[width=.17\textwidth]{figures/white lbox.jpg}}
    \caption{Lightbox-like backdrops}
    \label{fig:backdrops}
\end{figure}
Angle variety and image overlap was achieved by taking images in short intervals,
between either camera motion or object motion (ie. physical rotation). Overlap for 
large objects (ie. buildings) was achieved through capturing every 3-5 steps. 
\\
The overall methodology for capturing smaller objects throughout the project was 
based on \cite{temple} and \cite{viking}.



\subsection{Feature Preprocessing}
During feature extraction, further processing can be 
done to isolate key points on objects. We apply a combination of 
image filtering, blurring, and canny edge detection to build a binary mask
(show in Figure \ref{fig:mask}) covering the object of interest. 
\begin{figure}[ht!]
    \centering
    \subfloat[Initial Image]{\includegraphics[width=.2\textwidth]{figures/temple.png}}
    \
    \subfloat[Binary mask]{\includegraphics[width=.2\textwidth]{figures/temple_mask.png}}
    \caption{Binary Mask. Dataset from \cite{temple}}
    \label{fig:mask}
\end{figure}
This mask is used to discard key points which are determined to be background noise.
Preparation for canny edge detection involves noise reduction through a gaussian blur
for effective detection \cite{ced}. Though OpenCV's implementation \cite{ced_ocv}
applies a $5\times 5$ Gaussian kernel, further reduction is often necessary.
Additionally, we apply a DoG (shown in Figure \ref{fig:DoG_ppc}) based approach to accentuate edges and blobs 
for lower texture objects and noisier datasets. 
\begin{figure}[ht!]
    \centering
    \subfloat[Gaussian $g_0$]{\includegraphics[width=.2\textwidth]{figures/dog/g0.png}}
    \
    \subfloat[Scaled Gaussian $g_1$]{\includegraphics[width=.2\textwidth]{figures/dog/g1.png}}
    \\
    \subfloat[DoG ($g_1-g_0$)]{\includegraphics[width=.2\textwidth]{figures/dog/dog.png}} \
    \subfloat[Blurred DoG (smoothen noise; prep. for edge detection)]{\includegraphics[width=.2\textwidth]{figures/dog/bdog.png}}
    \\
    \subfloat[Mask (No DoG)]{\includegraphics[width=.2\textwidth]{figures/dog/bad_mask.png}}
    \
    \subfloat[Mask (DoG)]{\includegraphics[width=.2\textwidth]{figures/dog/mask.png}}
    \caption{Difference of Gaussian based preprocessing approach. ($\sigma$-scale factor $k=2$)
    Inspired by \cite{sift}.}
    \label{fig:DoG_ppc}
\end{figure}
Sobel filters applied in the horizontal and vertical directions 
allow us to obtain edge gradients and directions \cite{ced_ocv} as follows:
\[
    G = \sqrt{G_x^2 + G_y^2}, \ \ \ \theta = \arctan \left( \dfrac{G_y}{G_x} \right)
\] where $G$ is the edge gradient and $\theta$ is the edge direction.
\\
Non-maximum suppression removes unwanted pixels that may not be part of an edge \cite{ced_ocv}.
Hystersis thresholding determines edge criterion via a user defined 
lower-upper bound $(l,u)$:
\begin{enumerate}[i]
    \item $G > u$ $\to$ edge
    \item $G < l$ $\to$ not an edge
    \item $G \in [l,u]$ $\to$ classified based on connectivity to edge pixels
\end{enumerate}
We use the edge image, $E(x,y)$, to build a mask by:
\begin{enumerate}[1.]
    \item Convolving a Gaussian kernel on $E$
    \item Binary thresholding is applied to the convolved image (forming the initial mask $M$)
    \item Apply two median blur filters to $M$
\end{enumerate}
We can apply our mask to the source frame and exclude key points that
are irrelevant to the image. Though this does not directly affect the dense point cloud
reconstruction from MVS, it can decrease matches from background noise, thus 
improving match performance and the accuracy of two view geometry. A general 
outline of our feature preprocessing approach is shown in Figure \ref{fig:ppc_pipe}
and an example is how in Figure \ref{fig:ppc}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=.4\textwidth]{figures/preproc pipeline.png}
    \caption{Feature preprocessing pipeline.}
    \label{fig:ppc_pipe}
\end{figure}
\begin{figure}[ht!]
    \centering
    \subfloat[Source Image]{\includegraphics[width=.2\textwidth]{figures/ppc/src.png}}
    \
    \subfloat[BRISK keypoints]{\includegraphics[width=.2\textwidth]{figures/ppc/kp.png}}
    \\
    \subfloat[Edge]{\includegraphics[width=.13\textwidth]{figures/ppc/edge.png}}
    \
    \subfloat[Mask]{\includegraphics[width=.13\textwidth]{figures/ppc/mask.png}}
    \
    \subfloat[Masked image]{\includegraphics[width=.13\textwidth]{figures/ppc/mkp.png}}
    \caption{Feature preprocessing example. Dataset from \cite{viking}}
    \label{fig:ppc}
\end{figure}

\subsection{Point Cloud Processing}
This project uses Open3D's implementation of the Ball-Pivot Algorithm (BPA) \cite{bpa}
\cite{sr_o3d} and Poisson Surface Reconstruction (PSR) \cite{psr}\cite{sr_o3d}, 
two widely used mesh reconstruction techniques. 
BPA involves a “ball” with a user-defined radius, $r$, 
which pivots along a manifold surface of the 3D object.
Triangles are formed when the ball touches 3 points 
without “falling through”, eventually leading to a triangle mesh 
once all points are considered \cite{bpa}. This process can be 
repeated with various different radii to improve accuracy. 
An implementation trick we discovered with radii tuning was 
defining them as an array of scaled average neighbor distances. 
This approach often gave the best results with respect to BPA.
PSR \cite{psr} formalizes surface reconstruction as a 
poisson problem and creates very smooth surfaces that 
robustly approximate noisy data using a point cloud, 
its normals, and an octree of a user specified depth. 
However, PSR assumes the point cloud represents an object 
rather than the environment surrounding it, as such its 
robustness to noise is limited when background points are 
introduced. Additionally, BPA \cite{bpa} is generally 
not as robust as PSR for noise in an object point cloud, 
however it handles background noise well 
(given enough separation between points). 
To alleviate the effect of noise, we use 
Open3D's radial and statistical point cloud outlier removal 
algorithms to automate background noise removal \cite{pcr},
improving overall mesh quality for both approaches. 

\section{Results}
\subsection{Initial Evaluation}
Initial evaluation involved a direct benchmark of 
BRISK and SIFT feature detectors for various datasets. 
(Benchmarks were collected on the same Ryzen 9 5900HS 16GB RAM system on six datasets)
\begin{figure}[ht!]
    \centering
    \subfloat[SIFT Features]{\includegraphics[width=.2\textwidth]{figures/res/sift.png}}
    \
    \subfloat[BRISK Features]{\includegraphics[width=.2\textwidth]{figures/res/brisk.png}}
    \caption{SIFT vs BRISK detected features (ssd box)}
    \label{fig:br_vs_si}
\end{figure}
\begin{figure}[ht!]
    \centering
    \subfloat[SIFT Features]{\includegraphics[width=.2\textwidth]{figures/res/sift_temple.png}}
    \
    \subfloat[BRISK Features]{\includegraphics[width=.2\textwidth]{figures/res/brisk_temple.png}}
    \caption{SIFT vs BRISK detected features (templeRing \cite{temple})}
    \label{fig:brt_vs_sit}
\end{figure}
Both Figures \ref{fig:br_vs_si} and \ref{fig:brt_vs_sit}, as well as Table \ref{tbl:kpe_n}, 
demonstrate a substantial difference in overall ability. Referring to Figure \ref{fig:br_vs_si}, we see that 
SIFT detection is able to find nearly all the points BRISK detection finds, 
as well as
more subtle features like the entire edge of the box (which BRISK largely fails to detect).
In cases where these types of low-texture, subtle features are important, our BRISK-SIFT SFM 
may not be viable compared to traditional SIFT-SIFT. 
However, figure \ref{fig:brt_vs_sit} suggests that the more "nuanced" feature points
may also be more akin to noise (detections on black background) and unneeded. 
Furthermore, BRISK is considerably faster than SIFT ($\sim$2.3x faster) as seen in Table \ref{tbl:kpe_t}
and still produces a large number of high quality points in textured regions 
(ie. areas with text in Figure \ref{fig:br_vs_si})
(surprisingly, BRISK yields 29\% more points than SIFT does on average). 
\begin{table}[ht!]
    \centering
    \caption{Keypoint Extraction (No. of keypoints extracted)}
    \label{tbl:kpe_n}
    \begin{tblr}{|c|c|c|}
        \hline 
        Dataset & SIFT  & BRISK \\
        \hline \hline
        Temple Ring \cite{temple}& 39945 & 42789 \\
        \hline
        Viking \cite{viking} & 58604 & 145037 \\
        \hline
        Lego5 & 60767 & 53192 \\
        \hline
        Keyboard & 219924 & 204750
        \\
        \hline
        Ace Coffee Building & 164260 & 212897
        \\ \hline
    \end{tblr}
\end{table}


\begin{table}[ht!]
    \centering
    \caption{Keypoint Extraction (Time (s))}
    \label{tbl:kpe_t}
    \begin{tblr}{|c|c|c|}
        \hline 
        Dataset & SIFT  & BRISK \\
        \hline \hline
        Temple Ring \cite{temple}& 3.8003 & 1.2922 \\
        \hline
        Viking \cite{viking} & 5.3268 & 3.2936 \\
        \hline
        Lego5 & 87.4832 & 16.2658 \\
        \hline
        Keyboard & 44.5370 & 12.0966
        \\
        \hline
        Ace Coffee Building & 18.0179 & 7.2542
        \\ \hline
    \end{tblr}
\end{table}

\subsection{COLMAP Comparison}
We evaluate the results of BRISK-SIFT feature extraction against both 
traditional SIFT-SIFT (on our SFM stack) and results from COLMAP on 
the "templeRing" \cite{temple} dataset. 
% two datasets,
% "templeRing" \cite{temple} and "kb2". 
\begin{figure}[ht!]
    \centering
    \subfloat[BRISK-SIFT Sparse]
    {\includegraphics[width=.17\textwidth]{figures/colmap comp/sparse_brisk.png}}
    \ \ \ 
    \subfloat[SIFT-SIFT Sparse]
    {\includegraphics[width=.17\textwidth]{figures/colmap comp/sift sparse.png}}
    \\
    \subfloat[COLMAP Sparse]
    {\includegraphics[width=.4\textwidth]{figures/colmap comp/sparse colmap.png}}
    \caption{Sparse Reconstruction of our SFM stack (with BRISK-SIFT and SIFT-SIFT) and full COLMAP}
    \label{fig:temple_sparse_comp}
\end{figure}
In Figure \ref{fig:temple_sparse_comp}, we see that our SFM stack (for both
BRISK-SIFT and SIFT-SIFT) results in a sparser point cloud compared to 
pure COLMAP, however considerably less visible noise as well. 
With BRISK-SIFT in particular, our SFM stack results in a sparser point cloud
compared to other methods (likely due to less detections), however it also 
contains the least amount of noise in the reconstructed points. In 
Figure \ref{fig:temple_dense_comp}, we see that the dense reconstruction from 
COLMAP's MVS \cite{schoenberger2016mvs} with our BRISK-SIFT SFM stack is nearly identical to both 
our SIFT-SIFT and COLMAP with the exception of a small gap. This is likely due to 
the difference in matched features, causing slightly different camera and pose estimation.
Nonetheless, all these point clouds provide a reasonably accurate 3D represenation
of the object. 


\begin{figure}[ht!]
    \centering
    \subfloat[BRISK-SIFT Dense Rec.]
    {\includegraphics[width=.17\textwidth]{figures/colmap comp/dense brisk.png}}
    \ \ \ 
    \subfloat[SIFT-SIFT Dense Rec. (noisy off screen)]
    {\includegraphics[width=.17\textwidth]{figures/colmap comp/dense sift.png}}
    \\
    \subfloat[COLMAP Dense Rec.]
    {\includegraphics[width=.3\textwidth]{figures/colmap comp/dense colmap.png}}
    \caption{Dense Reconstruction of our SFM stack (with BRISK-SIFT and SIFT-SIFT) and full COLMAP}
    \label{fig:temple_dense_comp}
\end{figure}


\subsection{Feature Preprocessing Evaluation}
We evaluate our feature preprocessing 
(a method of key point cleanup during feature extraction) 
with a benchmark test 
(same as Table \ref{tbl:kpe_n} and Table \ref{tbl:kpe_t}) and 
a visual test on the "lego5" dataset. 
\subsubsection{Benchmarks}
\begin{table}[ht!]
    \centering
    \caption{Feature Preprocessing (Ft. Extraction Time (s))}
    \label{tbl:ppc_t}
    \begin{tblr}{|c|c|c|}
        \hline
        Dataset & No Img Preproc.  & Image Preproc. \\
        \hline \hline
        Temple Ring \cite{temple} & 1.2922 & 2.3747 \\
        \hline
        Viking \cite{viking} & 3.2936 & 4.6455 \\
        \hline
        SSD Box & 5.8452 & 9.6800 \\
        \hline
        Lego5 & 16.2658 & 30.7978 \\
        \hline
        Keyboard & 12.0966 & 22.5780 \\
        \hline
        Ace Coffee Building & 7.2542 & 12.3442
        \\
        \hline
    \end{tblr}
\end{table}


\begin{table}[ht!]
    \centering
    \caption{Feature Preprocessing (Ft. Matching Time (s))}
    \label{tbl:ppc_mt}
    \begin{tblr}{|c|c|c|}
        \hline
        Dataset & No Img Preproc.  & Image Preproc. \\
        \hline \hline
        Temple Ring \cite{temple} & 23.600 & 22.989 \\
        \hline
        Viking \cite{viking} & 88.046 & 87.223 \\
        \hline
        SSD Box & 38.348 & 36.611 \\
        \hline
        Lego5 & 104.346 & 101.194 \\
        \hline
        Keyboard & 178.749 & 178.099 \\
        \hline
        Ace Coffee Building & 77.786 & 72.757
        \\
        \hline
    \end{tblr}
\end{table}
Table \ref{tbl:ppc_mt} shows that feature preprocessing provides a marginal benefit 
for matching ($\sim$2\% reduction in time on average). However, Table \ref{tbl:ppc_t}
shows that it also causes a $\sim$70\% increase in feature extraction time (on average), 
significantly lengthening the overall search process for a slight refinement
($\sim$5\% less matches on average). Still, it is worth noting that the increased 
feature extraction times (Table \ref{tbl:ppc_t}) are still faster than
using SIFT (Table \ref{tbl:kpe_t})


\subsubsection{Visual Test}
To further evaluate feature preprocessing, we apply our DoG implementation to 
the "lego5" dataset. The resulting reconstructions are shown in Figures \ref{fig:ppc_sparse}
and \ref{fig:ppc_dense}. 
\begin{figure}[ht!]
    \centering
    \subfloat[No Ft. Preproc.]{\includegraphics[width=.15\textwidth]{figures/ppc/lego5/npp_sparse.png}}
    \
    \subfloat[Ft. Preproc.]{\includegraphics[width=.2\textwidth]{figures/ppc/lego5/pp_sparse.png}}
    \caption{Sparse Reconstruction without vs with ft. preprocessing}
    \label{fig:ppc_sparse}
\end{figure}
From Figure \ref{fig:ppc_sparse}, we see that there is much more noise in the
non-feature preprocessed sparse reconstruction. 

\begin{figure}[ht!]
    \centering
    \subfloat[No Ft. Preproc.]{\includegraphics[width=.13\textwidth]{figures/ppc/lego5/npp_dense.png}}
    \
    \subfloat[Ft. Preproc.]{\includegraphics[width=.13\textwidth]{figures/ppc/lego5/pp_dense.png}}
    \caption{Dense Reconstruction without vs with ft. preprocessing}
    \label{fig:ppc_dense}
\end{figure}
The dense reconstruction of the feature preprocessed dataset (shown in 
Figure \ref{fig:ppc_dense}) also appears to be denser than the non-preprocessed
dataset (note the legs). Feature match refinement from preprocessing
is shown in Figure \ref{fig:ppc_fmatch}. This is especially useful in cases where
the object moves independent of the environment (ie. user rotates object rather 
than using camera motion).

\begin{figure}[ht!]
    \centering
    \subfloat[No Ft. Preproc.]
    {\includegraphics[width=.4\textwidth]{figures/ppc/matches/before.png}}
    \\
    \subfloat[With Ft. Preproc.]{
    {\includegraphics[width=.4\textwidth]{figures/ppc/matches/after.png}}
    }
    \caption{Feature Matches without vs with Feature Preproccessing 
    on lego5 sample image}
    \label{fig:ppc_fmatch}
\end{figure}
% \subsection{Feature Matching Evaluation (Benchmarking)}
% Benchmark evaluation of our feature matching (approx. nearest neighbor,
% MAGSAC++, etc.) against COLMAP.
% \begin{table}[ht!]
%     \centering
%     \label{tbl:match_t}
%     \caption{Matching Time (s)}
%     \begin{tblr}{|c|c|c|}
%         \hline
%         Dataset & COLMAP  & Ours (MAGSAC++, etc.) \\
%         \hline \hline
%         Temple Ring \cite{temple} & 11.548 & 23.600 \\
%         \hline
%         Viking \cite{viking} & 13.098 & 88.046 \\
%         \hline
%         SSD Box & 20.277 & 38.348 \\
%         \hline
%         Lego5 & 79.560 & 104.346 \\
%         \hline
%         Keyboard & 320.918 & 178.749 \\
%         \hline
%         Ace Coffee Building & 81.414 & 77.786
%         \\
%         \hline
%     \end{tblr}
% \end{table}

% \begin{table}[ht!]
%     \centering
%     \label{tbl:match_c}
%     \caption{Match Count}
%     \begin{tblr}{|c|c|c|}
%         \hline
%         Dataset & COLMAP  & Ours (MAGSAC++, etc.) \\
%         \hline \hline
%         Temple Ring \cite{temple} & 103481 & 23222 \\
%         \hline
%         Viking \cite{viking} & 56929 & 48050 \\
%         \hline
%         SSD Box & 106321 & 53162 \\
%         \hline
%         Lego5 & 131052 & 70341 \\
%         \hline
%         Keyboard & 202003 & 46002 \\
%         \hline
%         Ace Coffee Building & 74156 & 43474
%         \\
%         \hline
%     \end{tblr}
% \end{table}
% From Tables \ref{tbl:match_t} and \ref{tbl:match_c}, we bear a high computational
% cost in our matching implementation, where we see a 2.2x average increase in 
% matching time (vs. COLMAP) while obtaining a 50\% reduction in match count. This
% is likely a result of 
\subsection{Noisy Data}
We evaluated our methodology on two "noisy" datasets, "lego" and "can."
The dense reconstruction from the lego dataset via 
our BRISK-SIFT SFM-MVS stack, as well as a sample image are found in 
Figure \ref{fig:lego_recn}.
\begin{figure}
    \centering
    \subfloat[Sample img]{\includegraphics[width=.2\textwidth]{figures/lego/sample_img.jpg}}
    \
    \subfloat[Dense Reconstruction]{\includegraphics[width=.2\textwidth]{figures/lego/lego_dense_brisk.png}}
    \caption{Lego dataset reconstruction}
    \label{fig:lego_recn}
\end{figure}
The reconstruction shown is relatively accurate with regards to the lego figure,
although it does fail to capture certain features (likely due to 
its flat texture and glossy finish). However, there is a significant amount of 
background noise, likely from elements such as the metal picture frame in the background.
\\
Reconstructions for the "can" dataset are shown in Figure \ref{fig:can_n}, and a sample 
image is shown in Figure \ref{fig:can_n_sampl}
\begin{figure}
    \centering
    \subfloat[SIFT-SIFT]{\includegraphics[width=.2\textwidth]{figures/can/sift.png}}
    \
    \subfloat[COLMAP]{\includegraphics[width=.2\textwidth]{figures/can/cmap.png}}
    \caption{Can dataset reconstruction}
    \label{fig:can_n}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=.2\textwidth]{figures/can/sample.jpeg}
    \caption{Sample image from "can"}
    \label{fig:can_n_sampl}
\end{figure}
Unfortunately, our BRISK-SIFT based SFM pipeline was unable to create 
sufficient matches for this object,
and thus could not create a reconstruction. We believe this is due to
a lack of viable edges as well as the can's glossy and reflective surface, 
making it difficult to satisfy the 9/16 condition \cite{brisk}. 
We believe the resultant point cloud representations shown in Figure \ref{fig:can_n}
are look poor for similar reasons (ie. glossy surface). 



\subsection{Point Cloud Processing Evaluation}
We evaluate our point cloud processing methodologies by applying them 
to the resultant point clouds of four datasets (via our SFM-MVS workflow).
These datasets are "lego", "templeRing" \cite{temple}, "Viking" \cite{viking}, 
and "ace." As mentioned in 
the previous section, the "lego" dataset results in a rather noisy reconstruction. 
Applying our outlier removal strategies, however, appear to significantly improve
it (Figure \ref{fig:lego_out}).

\begin{figure}[ht!]
    \centering
    \subfloat[Noisy Pointcloud]{\includegraphics[width=.2\textwidth]{figures/lego/lego_dense_brisk.png}}
    \
    \subfloat[Outlier Removal]{\includegraphics[width=.2\textwidth]{figures/lego/lego_dense_brisk_clean.png}}
    \caption{Outlier Removal on lego}
    \label{fig:lego_out}
\end{figure}
Similarly, we find that outlier processing can be applied to other, less 
noisy datasets to eliminate some unnecessary structure (refer to Figure \ref{fig:ocd}).
\begin{figure}
    \centering
    \subfloat[templeRing \cite{temple}]{\includegraphics[width=.1\textwidth]{figures/dense/temple_raw.png}}
    \
    \subfloat[Viking \cite{viking}]{\includegraphics[width=.1\textwidth]{figures/dense/viking_raw.png}}
    \
    \subfloat[ace]{\includegraphics[width=.2\textwidth]{figures/dense/ace_raw.png}}
    \caption{Raw point cloud reconstructions}
    \label{fig:rcd}
\end{figure}

\begin{figure}
    \centering
    \subfloat[templeRing \cite{temple}]{\includegraphics[width=.1\textwidth]{figures/dense/temple_cleaned.png}}
    \
    \subfloat[Viking \cite{viking}]{\includegraphics[width=.1\textwidth]{figures/dense/viking_cleaned.png}}
    \
    \subfloat[ace]{\includegraphics[width=.2\textwidth]{figures/dense/ace_cleaned.png}}
    \caption{Outlier removal}
    \label{fig:ocd}
\end{figure}

We can then apply our mesh reconstruction algorithms, shown in Figures 
\ref{fig:bpa_clean} and \ref{fig:psr_clean}. 

\begin{figure}[ht!]
    \centering
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/lego raw.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/temple_bpa_raw.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/viking_bpa_raw.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/ace_bpa_raw.png}}
    \caption{BPA on raw reconstructions}
    \label{fig:bpa_raw}
\end{figure}


\begin{figure}[ht!]
    \centering
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/lego clean.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/temple_bpa_cleaned.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/viking_bpa_cleaned.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/bpa/ace_bpa_cleaned.png}}
    \caption{BPA on outlier removed reconstructions}
    \label{fig:bpa_clean}
\end{figure}


\begin{figure}[ht!]
    \centering
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/lego_raw_psr.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/temple_psr_raw.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/viking_psr_raw.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/ace_psr_raw.png}}
    \caption{PSR on raw reconstructions}
    \label{fig:psr_raw}
\end{figure}

\begin{figure}[ht!]
    \centering
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/lego_clean_psr.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/temple_psr_cleaned.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/viking_psr_cleaned.png}}
    \
    \subfloat[]{\includegraphics[width=.1\textwidth]{figures/psr/ace_psr_cleaned.png}}
    \caption{PSR on outlier removed reconstructions}
    \label{fig:psr_clean}
\end{figure}

We can see that PSR is often times a better alternative to BPA as it provides a cleaner, 
higher quality mesh compared to BPA. However, significant environmental noise, as in 
Figure \ref{fig:psr_raw}, can cause diminished results. 

% \section{Results}

\section{Conclusion and Future Work}
This paper presents improvements to existing SFM-MVS pipelines. 
We proposed an alternative approach to feature extraction, 
by implementing BRISK features as a faster alternative to the SIFT features
commonly used in existing systems. Although there exist situations where
BRISK features are not as performant as SIFT, we believe that our SFM-MVS pipeline
can still be effective in most cases. 
Furthermore, we presented a feature preprocessing pipeline, 
which has shown to be effective at clearing background noise, 
and masking the object of interest. 
Additionally, we improved feature matching by implementing 
approximate nearest neighbor searches and match refinement 
through MAGSAC++. Visual analysis of different surface reconstruction 
techniques leads us to believe that PSR is superior for reconstructing 
meshes. We found throughout testing and evaluation that ideal image datasets 
require well textured objects, constant illumination conditions, 
smooth backdrops, a high quantity of images with sufficient visual
overlap and sufficient parallax. Our versatile system has proven to be 
capable of reconstructing high quality meshes in reasonable time, for 
datasets of varying complexity.


\subsection{Future Work}
There is significant room for future work to imrpove and extend our SFM-MVS system. One crucial 
improvement would be implementing CUDA libraries to increase the efficiency
of feature extraction, matching, incremental mapping, and surface reconstruction. 
Additionally, we would like to explore the implementation of a BRISK-like algorithm
on top of a DoG octave, with the goal of creating a pseudo SIFT-BRISK detection 
algorithm for more robust keypoints at similar speeds to BRISK. 
% \section{}





% \section{Conclusion}
% The conclusion goes here.




% conference papers do not normally have an appendix



% % use section* for acknowledgment
% \ifCLASSOPTIONcompsoc
%   % The Computer Society usually uses the plural form
%   \section*{Acknowledgments}
% \else
%   % regular IEEE prefers the singular form
%   \section*{Acknowledgment}
% \fi


\section*{Author Contributions}
Roderick Lan implemented the BRISK-SIFT feature extraction stack, feature matching,
the Difference of Gaussian method in feature preprocessing, point cloud outlier removal, 
and poisson surface reconstruction.
\\
Abdullah Khadeli implemented the feature preprocessing algorithm, interaction with
PyCOLMAP and COLMAP, and the ball pivot algorithm. Additionally, he handled 
benchmarking. 

% The authors would like to thank...





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
% \begin{thebibliography}{1}

% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

% \end{thebibliography}

\bibliographystyle{IEEEtran}
\bibliography{References}


% that's all folks
\end{document}


